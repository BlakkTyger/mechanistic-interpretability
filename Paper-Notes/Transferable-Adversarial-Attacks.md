# Universal and Transferable Adversarial Attacks on Aligned Language Models

[Link](https://arxiv.org/pdf/2307.15043) to the paper
[Link](https://github.com/llm-attacks/llm-attacks) to the github repository
